# Preprocessing the data

So to be fair "preprocessing" here is a bit of a misnomer since we're not actually doing any traditional neuroimaging-style preprocessing (Ã  la [fMRIPrep](https://fmriprep.org/en/stable/)).
However, since the only "raw" data we have right now is the HCP data downloaded in the [previous step](./accessing_data.md) we have to do a small bit of work.

To run all the data preprocessing you can use the command `make preprocess` from the root of the [repository](https://github.com/netneurolab/markello_spatialnulls).
Note that this command requires both [FreeSurfer](https://surfer.nmr.mgh.harvard.edu/fswiki/rel6downloads) and [Connectome Workbench](https://www.humanconnectome.org/software/get-connectome-workbench), so make sure you've [installed all the relevant software](./setting_up.md)!

## NeuroSynth data processing

We rely on data from [NeuroSynth](https://neurosynth.org) to run a number of analyses reported in our paper.
Since we were primarily trying to replicate the analyses run in [Alexander-Bloch et al., 2018, *NeuroImage*](https://doi.org/10.1016/j.neuroimage.2018.05.070), we followed (or attempted to follow) their processing to the letter.
Using the [NeuroSynth API](https://github.com/neurosynth/neurosynth) we ran 123 meta-analyses for terms in the NeuroSynth database overlapping with those in the [Cognitive Atlas](https://www.cognitiveatlas.org/).
It's important to note that the original authors used only 120 terms in their analyses; however, likely due to updates in the NeuroSynth database (or potentitally the Cognitive Atlas) since the original publication two years, the new intersection of the databases yielded [123 terms](https://github.com/netneurolab/markello_spatialnulls/blob/master/data/raw/neurosynth/terms.txt).
To ensure we were following Alexander-Bloch et al., the association maps generated from the meta-analyses were projected to the fsaverage5 surface using FreeSurfer's `mri_vol2surf` command.

Projected data were parcellated with two multi-resolution atlases: the dMRI-derived atlas from [Cammoun et al., 2012, *J Neurosci Methods*](https://doi.org/10.1016/j.jneumeth.2011.09.031) and the fMRI-derived atlas from [Schaefer et al., 2018, *Cereb Cortex*](https://doi.org/10.1093/cercor/bhx179).
For the Cammoun atlas we used the fsaverage5 annotations generated by our lab and [available on OSF](https://osf.io/cwj3e/); for the Schaefer atlas we used the annotations [provided by the original authors](https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal/Parcellations/FreeSurfer5.3/fsaverage5/label).

All code for processing of NeuroSynth data can be found in [`scripts/01_preprocess/fetch_neurosynth_maps.py`](https://github.com/netneurolab/markello_spatialnulls/blob/master/scripts/01_preprocess/fetch_neurosynth_maps.py).
(Note: we strongly encourage you use the fantastic [NiMARE package](https://github.com/neurostuff/NiMARE) in the future instead of the now-deprecated NeuroSynth API.)

## HCP data processing

[Data from HCP](./accessing_data.md) come in CIFTI format, s the first step of processing involved splitting the data into two GIFTI files using Connectome Workbench's `wb_command` (#CIFTIhatersunite).
Then, to be equivalent with the NeuroSynth data processing pipelines, data were resampled from the fslr32k surface to the fsaverage5 surface.
Resampled data were parcellated with the Cammoun and Schaefer atlases.

All code for processing of HCP data can be found in [`scripts/01_preprocess/fetch_hcp_myelin.py`](https://github.com/netneurolab/markello_spatialnulls/blob/master/scripts/01_preprocess/fetch_hcp_myelin.py).
